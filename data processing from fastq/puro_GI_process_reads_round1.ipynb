{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3deb55cf-e477-4d57-a07b-b08c5ae89696",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3680dc63-62be-4b7f-8892-7200d2698d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = str.maketrans('ATGC', 'TACG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7a657d2-7547-41c2-9fce-87120cfeb65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from isotonic_barcode_calling import *\n",
    "import parallel_process_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00017747-e17c-4638-a357-7687f2c7b1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimum score (out of 100) on fuzzy protospacer matching\n",
    "MATCHING_THRESHOLD = 80\n",
    "# number of workers for distance computation in calling\n",
    "NUM_WORKERS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a018769d-02fb-43c0-814d-7b12e547ade8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY = \"/data1/normantm/angel/sequencing/AP1_816_puro_run1_output/Samples/DefaultProject\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78e6da5c-ceb6-4635-a627-a259f6aa37eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_folder_names(directory):\n",
    "    # List all entries in the directory\n",
    "    entries = os.listdir(directory)\n",
    "    \n",
    "    # Filter out only folders\n",
    "    folders = sorted([entry for entry in entries if os.path.isdir(os.path.join(directory, entry))])\n",
    "    \n",
    "    return folders\n",
    "\n",
    "SAMPLE_NAMES = get_folder_names(DIRECTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8e1ddd0-ac0d-409d-8f28-993da1ac0bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcodes = pd.read_csv(\"120k_barcodes.csv\", header=None)[1].str[30:55].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c6276cb-69b9-4b44-ab53-3836cf217608",
   "metadata": {},
   "outputs": [],
   "source": [
    "K562_separate_sgRNA1 = pd.read_csv(\"twist_K562_816_separate_sgRNA1.csv\", header=None, index_col=0)\n",
    "K562_separate_sgRNA2 = pd.read_csv(\"twist_K562_816_separate_sgRNA2.csv\", header=None, index_col=0)\n",
    "\n",
    "K562_separate_sgRNA1[\"sgRNA1\"] = K562_separate_sgRNA1[1].str[34:54].str.translate(trans).str[::-1]\n",
    "K562_separate_sgRNA2[\"sgRNA2\"] = K562_separate_sgRNA2[1].str[70:90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0721aa7-118f-44dc-bf9b-66825c0039a8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def process_sample(sample, separate_sgRNA1, separate_sgRNA2, run_name, output_dir):\n",
    "    print(\"reading fastq files\")\n",
    "    umi, umi_quality = process_files.read_fastq(f\"{DIRECTORY}/{sample}/{sample}_UMI_I1.fastq.gz\")\n",
    "    g2 = process_files.read_fastq_g2(f\"{DIRECTORY}/{sample}/{sample}_R2.fastq.gz\")\n",
    "    b = process_files.read_fastq_b(f\"{DIRECTORY}/{sample}/{sample}_R2.fastq.gz\")\n",
    "    g1 = process_files.read_fastq_g1(f\"{DIRECTORY}/{sample}/{sample}_R1.fastq.gz\")\n",
    "    \n",
    "    unique_b = np.unique(b)\n",
    "    unique_p1 = np.unique(g1)\n",
    "    unique_p2 = np.unique(g2)\n",
    "\n",
    "    print(\"mapping barcodes\")\n",
    "    with open(f\"/data1/normantm/angel/freebarcodes/{run_name}_unique_b_{sample}.fastq\", \"w\") as f:\n",
    "        for i, ba in enumerate(unique_b):\n",
    "            f.write(f\"@{i}\\n\")\n",
    "            ba_new = ba.replace(\"N\", \"C\")\n",
    "            f.write(f\"{ba_new}\\n\")\n",
    "            f.write(\"+\\n\")\n",
    "            Q = ['I']*25\n",
    "            for i in re.finditer(\"N\", ba):\n",
    "                Q[i.start()] = \"!\"\n",
    "            Q = \"\".join(Q)\n",
    "            f.write(f\"{Q}\\n\")\n",
    "            \n",
    "    os.system(\"freebarcodes decode /data1/normantm/angel/freebarcodes/120k_barcodes15-2.txt,/data1/normantm/angel/freebarcodes/120k_barcodes10-1.txt \" +\\\n",
    "              f\"/data1/normantm/angel/freebarcodes/{run_name}_unique_b_{sample}.fastq --output-dir /data1/normantm/angel/freebarcodes/\")\n",
    "    \n",
    "    decoded_unique_b = pd.read_csv(f\"/data1/normantm/angel/freebarcodes/{run_name}_unique_b_{sample}_decoded.txt\", sep=\"\\t\", header=None, index_col=0)\n",
    "    decoded_unique_b.columns = [\"b15\", \"b10\", \"seq\"]\n",
    "    decoded_unique_b[\"barcode_mapped\"] = decoded_unique_b[\"b15\"] + decoded_unique_b[\"b10\"]\n",
    "    decoded_unique_b.drop_duplicates(inplace=True)\n",
    "    decoded_unique_b.query(\"barcode_mapped in @barcodes\", inplace=True)\n",
    "    decoded_unique_b.set_index(\"seq\", inplace=True)\n",
    "\n",
    "    print(\"aligning protospacers\")\n",
    "    alignments_p1 = chunked_call_alignments_new(unique_p1, separate_sgRNA1.sgRNA1, num_chunks=int(len(unique_p1)/1000), num_workers=NUM_WORKERS)\n",
    "    alignments_p2 = chunked_call_alignments_new(unique_p2, separate_sgRNA2.sgRNA2, num_chunks=int(len(unique_p2)/1000), num_workers=NUM_WORKERS)\n",
    "    alignments_p1.query(\"score >= @MATCHING_THRESHOLD\", inplace=True)\n",
    "    alignments_p2.query(\"score >= @MATCHING_THRESHOLD\", inplace=True)\n",
    "\n",
    "    print(\"filtering reads\")\n",
    "    idx_p1 = np.array([r in alignments_p1.index for r in g1])\n",
    "    idx_p2 = np.array([r in alignments_p2.index for r in g2])\n",
    "    idx_b = np.array([r in decoded_unique_b.index for r in b])\n",
    "    \n",
    "    filtered_idx = idx_p1 & idx_p2 & idx_b\n",
    "    \n",
    "    g1, g2 = g1[filtered_idx], g2[filtered_idx]\n",
    "    b = b[filtered_idx]\n",
    "    umi = umi[filtered_idx]\n",
    "    umi_quality = umi_quality[filtered_idx]\n",
    "\n",
    "    print(\"writing to files\")\n",
    "    with open(f\"{output_dir}/processed_filtered_reads_{sample}.csv\", \"a\") as f:\n",
    "        f.write(\"p1_identity,p2_identity,barcode_mapped,UMI\\n\")\n",
    "    \n",
    "        size = 2000000\n",
    "        chunks = np.arange(0, len(g1), size)\n",
    "        \n",
    "        for i in chunks:\n",
    "            \n",
    "            lines = np.array([alignments_p1.loc[g1[i:i+size]].identity.values,\n",
    "                              alignments_p2.loc[g2[i:i+size]].identity.values,\n",
    "                              decoded_unique_b.loc[b[i:i+size]].barcode_mapped.values,\n",
    "                              umi[i:i+size]])\n",
    "            \n",
    "            lines = [\",\".join(a)+\"\\n\" for a in lines.T]\n",
    "            \n",
    "            f.writelines(lines)\n",
    "            \n",
    "    with open(f\"{output_dir}/filtered_idx_{sample}.npy\", 'wb') as f:\n",
    "        np.save(f, filtered_idx)\n",
    "        \n",
    "    #with open(f\"{output_dir}/UMI_quality_score_{sample}.npy\", 'wb') as f:\n",
    "    #    np.save(f, umi_quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77c7658d-0b79-443d-ab68-d5f476654c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sample(sample, separate_sgRNA1, separate_sgRNA2, run_name, output_dir):\n",
    "    print(\"reading UMI\")\n",
    "    umi = parallel_process_files.fast_fastq_sequences(f\"{DIRECTORY}/{sample}/{sample}_UMI_I1.fastq.gz\", pigz_threads=4)\n",
    "    print(\"reading guide 2\")\n",
    "    g2 = parallel_process_files.parallel_extract_protospacer2(f\"{DIRECTORY}/{sample}/{sample}_R2.fastq.gz\",\n",
    "                                                              workers=12, chunksize=1000000, pigz_threads=4)\n",
    "    print(\"reading barcode\")\n",
    "    b = parallel_process_files.parallel_barcode_extractor(f\"{DIRECTORY}/{sample}/{sample}_R2.fastq.gz\",\n",
    "                                                          workers=12, chunksize=1000000, pigz_threads=4)\n",
    "    print(\"reading guide 1\")\n",
    "    g1 = parallel_process_files.parallel_protospacer_extractor(f\"{DIRECTORY}/{sample}/{sample}_R1.fastq.gz\", \n",
    "                                                               five_bp=\"TAAAC\", workers=12, chunksize=1000000,\n",
    "                                                               pigz_threads=4)\n",
    "    \n",
    "    unique_b = pd.unique(b)\n",
    "\n",
    "    print(\"mapping barcodes\")\n",
    "    with open(f\"/data1/normantm/angel/freebarcodes/{run_name}_unique_b_{sample}.fastq\", \"w\") as f:\n",
    "        for i, ba in enumerate(unique_b):\n",
    "            if \"N\" in ba:\n",
    "                continue\n",
    "            f.write(f\"@{i}\\n\")\n",
    "            f.write(f\"{ba}\\n\")\n",
    "            f.write(\"+\\n\")\n",
    "            Q = ['I']*25\n",
    "            Q = \"\".join(Q)\n",
    "            f.write(f\"{Q}\\n\")\n",
    "            \n",
    "    os.system(\"freebarcodes decode /data1/normantm/angel/freebarcodes/120k_barcodes15-2.txt,/data1/normantm/angel/freebarcodes/120k_barcodes10-1.txt \" +\\\n",
    "              f\"/data1/normantm/angel/freebarcodes/{run_name}_unique_b_{sample}.fastq --output-dir /data1/normantm/angel/freebarcodes/\")\n",
    "    \n",
    "    decoded_unique_b = pd.read_csv(f\"/data1/normantm/angel/freebarcodes/{run_name}_unique_b_{sample}_decoded.txt\", sep=\"\\t\", header=None, index_col=0)\n",
    "    decoded_unique_b.columns = [\"b15\", \"b10\", \"seq\"]\n",
    "    decoded_unique_b[\"barcode_mapped\"] = decoded_unique_b[\"b15\"] + decoded_unique_b[\"b10\"]\n",
    "    decoded_unique_b.drop_duplicates(inplace=True)\n",
    "    decoded_unique_b.query(\"barcode_mapped in @barcodes\", inplace=True)\n",
    "    decoded_unique_b.set_index(\"seq\", inplace=True)\n",
    "\n",
    "    print(\"aligning protospacers\")\n",
    "    idx_b = pd.Index(b).isin(decoded_unique_b.index)\n",
    "\n",
    "    filtered_g1 = g1[idx_b]\n",
    "    filtered_g2 = g2[idx_b]\n",
    "    unique_p = pd.unique(np.concatenate([pd.unique(filtered_g1), pd.unique(filtered_g2)]))\n",
    "\n",
    "    alignments_p = chunked_call_alignments_new(unique_p, separate_sgRNA1.sgRNA1, num_chunks=int(len(unique_p)/1000), num_workers=NUM_WORKERS)\n",
    "    alignments_p.to_csv(f\"{output_dir}/{sample}_guide_alignments.csv\")\n",
    "    alignments_p.query(\"score >= @MATCHING_THRESHOLD\", inplace=True)\n",
    "\n",
    "    print(\"filtering reads\")\n",
    "    idx_p1 = pd.Index(g1).isin(alignments_p.index)\n",
    "    idx_p2 = pd.Index(g2).isin(alignments_p.index)\n",
    "    idx_umi = np.char.find(umi, \"N\") == -1\n",
    "    \n",
    "    filtered_idx = idx_p1 & idx_p2 & idx_b & idx_umi\n",
    "    \n",
    "    g1, g2 = g1[filtered_idx], g2[filtered_idx]\n",
    "    b = b[filtered_idx]\n",
    "    umi = umi[filtered_idx]\n",
    "\n",
    "    print(\"writing to files\")\n",
    "    with open(f\"{output_dir}/new_processed_filtered_reads_{sample}.csv\", \"a\") as f:\n",
    "        f.write(\"p1_identity,p2_identity,p1_score,p2_score,barcode_mapped,UMI\\n\")\n",
    "    \n",
    "        size = 2000000\n",
    "        chunks = np.arange(0, len(g1), size)\n",
    "        \n",
    "        for i in chunks:\n",
    "                \n",
    "            lines = np.array([alignments_p.loc[g1[i:i+size]].identity.values,\n",
    "                              alignments_p.loc[g2[i:i+size]].identity.values,\n",
    "                              alignments_p.loc[g1[i:i+size]].score.values.astype(int).astype(str),\n",
    "                              alignments_p.loc[g2[i:i+size]].score.values.astype(int).astype(str),\n",
    "                              decoded_unique_b.loc[b[i:i+size]].barcode_mapped.values,\n",
    "                              umi[i:i+size]])\n",
    "                \n",
    "            lines = [\",\".join(a)+\"\\n\" for a in lines.T]\n",
    "            \n",
    "            f.writelines(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e19266f-0d3c-4b42-996a-72b83f081c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"/data1/normantm/angel/sequencing/AP1_816_puro_run1_output\"\n",
    "run_name = \"20250321_K562_AP1_816_puro_run1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b9291f-51f6-46bf-97c4-96d2d0430b48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for sample in SAMPLE_NAMES:\n",
    "    process_sample(sample, K562_separate_sgRNA1, K562_separate_sgRNA2, run_name, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bcecc53f-7116-4a61-92fc-06e82dbb52c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY = \"/data1/normantm/angel/sequencing/AP1_816_puro_run2_output/Samples/DefaultProject\"\n",
    "SAMPLE_NAMES = get_folder_names(DIRECTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28aae3bd-09ad-4f4e-92d1-5a4562c5d39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"/data1/normantm/angel/sequencing/AP1_816_puro_run2_output\"\n",
    "run_name = \"20250321_K562_AP1_816_puro_run2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f72490-de62-4adf-9c66-50baadb388aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for sample in SAMPLE_NAMES:\n",
    "    process_sample(sample, K562_separate_sgRNA1, K562_separate_sgRNA2, run_name, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117fc8f0-f51a-48c4-8044-853659fb61eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (angel)",
   "language": "python",
   "name": "angel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
