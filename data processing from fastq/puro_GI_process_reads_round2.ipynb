{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3deb55cf-e477-4d57-a07b-b08c5ae89696",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3680dc63-62be-4b7f-8892-7200d2698d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = str.maketrans('ATGC', 'TACG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7a657d2-7547-41c2-9fce-87120cfeb65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from isotonic_barcode_calling import *\n",
    "import parallel_process_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00017747-e17c-4638-a357-7687f2c7b1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimum score (out of 100) on fuzzy protospacer matching\n",
    "MATCHING_THRESHOLD = 80\n",
    "IDX_THRESHOLD = 75\n",
    "# number of workers for distance computation in calling\n",
    "NUM_WORKERS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a018769d-02fb-43c0-814d-7b12e547ade8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY = \"/data1/normantm/angel/sequencing/AP1_816_puro_round2_1_output_NoFilter/Samples/DefaultProject\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78e6da5c-ceb6-4635-a627-a259f6aa37eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_folder_names(directory):\n",
    "    # List all entries in the directory\n",
    "    entries = os.listdir(directory)\n",
    "    \n",
    "    # Filter out only folders\n",
    "    folders = sorted([entry for entry in entries if os.path.isdir(os.path.join(directory, entry))])\n",
    "    \n",
    "    return folders\n",
    "\n",
    "SAMPLE_NAMES = get_folder_names(DIRECTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8e1ddd0-ac0d-409d-8f28-993da1ac0bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcodes = pd.read_csv(\"120k_barcodes.csv\", header=None)[1].str[30:55].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c6276cb-69b9-4b44-ab53-3836cf217608",
   "metadata": {},
   "outputs": [],
   "source": [
    "K562_separate_sgRNA1 = pd.read_csv(\"twist_K562_816_separate_sgRNA1.csv\", header=None, index_col=0)\n",
    "K562_separate_sgRNA2 = pd.read_csv(\"twist_K562_816_separate_sgRNA2.csv\", header=None, index_col=0)\n",
    "\n",
    "K562_separate_sgRNA1[\"sgRNA1\"] = K562_separate_sgRNA1[1].str[34:54].str.translate(trans).str[::-1]\n",
    "K562_separate_sgRNA2[\"sgRNA2\"] = K562_separate_sgRNA2[1].str[70:90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cc5c7df-cbfb-45f3-9a40-4dc4c6e14891",
   "metadata": {},
   "outputs": [],
   "source": [
    "i1_map = pd.Series({\n",
    "    \"1_1\": \"CGTACTAG\",\n",
    "    \"1_2\": \"AGGCAGAA\", \n",
    "    \"1_3\": \"TCCTGAGC\",\n",
    "    \"2_1\": \"GGACTCCT\",\n",
    "    \"2_2\": \"TAGGCATG\",\n",
    "    \"2_3\": \"CTCTCTAC\",\n",
    "    \"3_1\": \"AAGAGGCA\",\n",
    "    \"3_2\": \"GTAGAGGA\",\n",
    "    \"3_3\": \"GCTCATGA\"\n",
    "    })\n",
    "i2_map = pd.Series({\"identity\": \"TAGATCGC\", \"reporter\": \"CTCTCTAT\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0721aa7-118f-44dc-bf9b-66825c0039a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sample(sample, separate_sgRNA1, separate_sgRNA2, i1_map, i2_map, run_name, output_dir):\n",
    "    print(\"reading UMI\")\n",
    "    umi = parallel_process_files.fast_fastq_sequences(f\"{DIRECTORY}/{sample}/{sample}_UMI_I1.fastq.gz\", pigz_threads=4)\n",
    "    print(\"reading guide 2\")\n",
    "    g2 = parallel_process_files.parallel_extract_protospacer2(f\"{DIRECTORY}/{sample}/{sample}_R2.fastq.gz\",\n",
    "                                                              workers=12, chunksize=1000000, pigz_threads=4)\n",
    "    print(\"reading barcode\")\n",
    "    b = parallel_process_files.parallel_barcode_extractor(f\"{DIRECTORY}/{sample}/{sample}_R2.fastq.gz\",\n",
    "                                                          workers=12, chunksize=1000000, pigz_threads=4)\n",
    "    print(\"reading guide 1\")\n",
    "    g1 = parallel_process_files.parallel_protospacer_extractor(f\"{DIRECTORY}/{sample}/{sample}_R1.fastq.gz\", \n",
    "                                                               five_bp=\"TAAAC\", workers=12, chunksize=1000000,\n",
    "                                                               pigz_threads=4)\n",
    "    print(\"reading index 1\")\n",
    "    i1 = parallel_process_files.fast_fastq_sequences(f\"{DIRECTORY}/{sample}/{sample}_I1.fastq.gz\", pigz_threads=4)\n",
    "    print(\"reading index 2\")\n",
    "    i2 = parallel_process_files.fast_fastq_sequences(f\"{DIRECTORY}/{sample}/{sample}_I2.fastq.gz\", pigz_threads=4)\n",
    "    \n",
    "    unique_b = pd.unique(b)\n",
    "    unique_i1 = pd.unique(i1)\n",
    "    unique_i2 = pd.unique(i2)\n",
    "\n",
    "    print(\"mapping barcodes\")\n",
    "    with open(f\"/data1/normantm/angel/freebarcodes/{run_name}_unique_b_{sample}.fastq\", \"w\") as f:\n",
    "        for i, ba in enumerate(unique_b):\n",
    "            if \"N\" in ba:\n",
    "                continue\n",
    "            f.write(f\"@{i}\\n\")\n",
    "            f.write(f\"{ba}\\n\")\n",
    "            f.write(\"+\\n\")\n",
    "            Q = ['I']*25\n",
    "            Q = \"\".join(Q)\n",
    "            f.write(f\"{Q}\\n\")\n",
    "            \n",
    "    os.system(\"freebarcodes decode /data1/normantm/angel/freebarcodes/120k_barcodes15-2.txt,/data1/normantm/angel/freebarcodes/120k_barcodes10-1.txt \" +\\\n",
    "              f\"/data1/normantm/angel/freebarcodes/{run_name}_unique_b_{sample}.fastq --output-dir /data1/normantm/angel/freebarcodes/\")\n",
    "    \n",
    "    decoded_unique_b = pd.read_csv(f\"/data1/normantm/angel/freebarcodes/{run_name}_unique_b_{sample}_decoded.txt\", sep=\"\\t\", header=None, index_col=0)\n",
    "    decoded_unique_b.columns = [\"b15\", \"b10\", \"seq\"]\n",
    "    decoded_unique_b[\"barcode_mapped\"] = decoded_unique_b[\"b15\"] + decoded_unique_b[\"b10\"]\n",
    "    decoded_unique_b.drop_duplicates(inplace=True)\n",
    "    decoded_unique_b.query(\"barcode_mapped in @barcodes\", inplace=True)\n",
    "    decoded_unique_b.set_index(\"seq\", inplace=True)\n",
    "\n",
    "    print(\"aligning protospacers\")\n",
    "    idx_b = pd.Index(b).isin(decoded_unique_b.index)\n",
    "\n",
    "    filtered_g1 = g1[idx_b]\n",
    "    filtered_g2 = g2[idx_b]\n",
    "    unique_p = pd.unique(np.concatenate([pd.unique(filtered_g1), pd.unique(filtered_g2)]))\n",
    "\n",
    "    alignments_p = chunked_call_alignments_new(unique_p, separate_sgRNA1.sgRNA1, num_chunks=int(len(unique_p)/1000), num_workers=NUM_WORKERS)\n",
    "    alignments_p.to_csv(f\"{output_dir}/guide_alignments.csv\")\n",
    "    alignments_p.query(\"score >= @MATCHING_THRESHOLD\", inplace=True)\n",
    "\n",
    "    print(\"mapping indices\")\n",
    "    alignments_i1 = chunked_call_alignments_new(unique_i1, i1_map, num_chunks=int(len(unique_i1)/1000), num_workers=NUM_WORKERS)\n",
    "    alignments_i2 = chunked_call_alignments_new(unique_i2, i2_map, num_chunks=int(len(unique_i2)/1000), num_workers=NUM_WORKERS)\n",
    "    alignments_i1.query(\"score >= @IDX_THRESHOLD\", inplace=True)\n",
    "    alignments_i2.query(\"score >= @IDX_THRESHOLD\", inplace=True)\n",
    "\n",
    "    print(\"filtering reads\")\n",
    "    idx_p1 = pd.Index(g1).isin(alignments_p.index)\n",
    "    idx_p2 = pd.Index(g2).isin(alignments_p.index)\n",
    "    idx_i1 = pd.Index(i1).isin(alignments_i1.index)\n",
    "    idx_i2 = pd.Index(i2).isin(alignments_i2.index)\n",
    "    idx_umi = np.char.find(umi, \"N\") == -1\n",
    "    \n",
    "    filtered_idx = idx_p1 & idx_p2 & idx_b & idx_i1 & idx_i2 & idx_umi\n",
    "    \n",
    "    g1, g2 = g1[filtered_idx], g2[filtered_idx]\n",
    "    b = b[filtered_idx]\n",
    "    umi = umi[filtered_idx]\n",
    "    i1, i2 = i1[filtered_idx], i2[filtered_idx]\n",
    "\n",
    "    print(\"writing to files\")\n",
    "    with open(f\"{output_dir}/processed_filtered_reads_{sample}.csv\", \"a\") as f:\n",
    "        f.write(\"p1_identity,p2_identity,p1_score,p2_score,sample,transcript,barcode_mapped,UMI\\n\")\n",
    "    \n",
    "        size = 2000000\n",
    "        chunks = np.arange(0, len(g1), size)\n",
    "        \n",
    "        for i in chunks:\n",
    "                \n",
    "            lines = np.array([alignments_p.loc[g1[i:i+size]].identity.values,\n",
    "                              alignments_p.loc[g2[i:i+size]].identity.values,\n",
    "                              alignments_p.loc[g1[i:i+size]].score.values.astype(int).astype(str),\n",
    "                              alignments_p.loc[g2[i:i+size]].score.values.astype(int).astype(str),\n",
    "                              alignments_i1.loc[i1[i:i+size]].identity.values,\n",
    "                              alignments_i2.loc[i2[i:i+size]].identity.values,\n",
    "                              decoded_unique_b.loc[b[i:i+size]].barcode_mapped.values,\n",
    "                              umi[i:i+size]])\n",
    "                \n",
    "            lines = [\",\".join(a)+\"\\n\" for a in lines.T]\n",
    "            \n",
    "            f.writelines(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e19266f-0d3c-4b42-996a-72b83f081c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"/data1/normantm/angel/sequencing/AP1_816_puro_round2_1_output_NoFilter\"\n",
    "run_name = \"K562_AP1_816_puro_round2_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b9291f-51f6-46bf-97c4-96d2d0430b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in SAMPLE_NAMES:\n",
    "   process_sample(sample, K562_separate_sgRNA1, K562_separate_sgRNA2, i1_map, i2_map, run_name, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23c1f9f-cbf6-4da4-aecf-75a3d1357cc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (angel)",
   "language": "python",
   "name": "angel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
